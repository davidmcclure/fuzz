{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "import ujson\n",
    "\n",
    "import dateutil.parser\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from cached_property import cached_property\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import islice\n",
    "from boltons.iterutils import chunked_iter, windowed_iter\n",
    "from datetime import datetime as dt\n",
    "from collections import UserDict\n",
    "\n",
    "from sent_order.models import kt_regression as kt_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dclure/Projects/infuzzy/env/lib/python3.6/site-packages/torch/serialization.py:316: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTM' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "sent_encoder = torch.load(\n",
    "    '../../plot-ordering/data/models/new/kt-reg/sent_encoder.68.bin',\n",
    "    map_location={'cuda:0': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub('[\\s]{2,}|\\n', ' ', text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Sentence:\n",
    "    \n",
    "    text = attr.ib()\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self.text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    def tokens(self):\n",
    "        return [t.text for t in self.doc]\n",
    "    \n",
    "    def sent_order_x(self):\n",
    "        return kt_reg.Sentence(self.tokens()).variable()\n",
    "    \n",
    "    def embedding(self):\n",
    "        x = self.sent_order_x()\n",
    "        return sent_encoder([x])[0].data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class NewspaperSegment:\n",
    "    \n",
    "    path = attr.ib()\n",
    "    \n",
    "    def text(self):\n",
    "        with open(self.path) as fh:\n",
    "            return clean_text(fh.read())\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self.text(), disable=['tokenizer', 'parser', 'tagger', 'ner'])\n",
    "    \n",
    "    @cached_property\n",
    "    def paper_name(self):\n",
    "        return self.path.split(os.sep)[-3]\n",
    "    \n",
    "    @cached_property\n",
    "    def date(self):\n",
    "        return dt.strptime(self.path.split(os.sep)[-2], '%m-%d-%Y')\n",
    "    \n",
    "    def sentence_texts(self):\n",
    "        for sent in self.doc.sents:\n",
    "            yield sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class NewspaperCorpus:\n",
    "    \n",
    "    root = attr.ib()\n",
    "    \n",
    "    def paths(self):\n",
    "        return glob(os.path.join(self.root, '**/*.txt'), recursive=True)\n",
    "    \n",
    "    def segments(self):\n",
    "        for path in tqdm_notebook(self.paths()):\n",
    "            yield NewspaperSegment(path)\n",
    "            \n",
    "    def df_rows(self):\n",
    "        for segment in self.segments():\n",
    "            for text in segment.sentence_texts():\n",
    "                yield dict(paper_name=segment.paper_name, date=segment.date, text=text)\n",
    "                \n",
    "    def df(self, skim=None):\n",
    "        return pd.DataFrame(list(islice(self.df_rows(), skim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoutubeTranscript(UserDict):\n",
    "    \n",
    "    @classmethod\n",
    "    def from_path(cls, path):\n",
    "        with open(path) as fh:\n",
    "            return cls(ujson.load(fh))\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self['transcript'], disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    @cached_property\n",
    "    def published_at(self):\n",
    "        return dateutil.parser.parse(self['published_at'])\n",
    "    \n",
    "    def sentence_texts(self, size=10):\n",
    "        for chunk in windowed_iter(self.doc, size):\n",
    "            yield ' '.join([t.text for t in chunk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class YoutubeCorpus:\n",
    "    \n",
    "    root = attr.ib()\n",
    "    \n",
    "    def paths(self):\n",
    "        return glob(os.path.join(self.root, '**/*.json'), recursive=True)\n",
    "    \n",
    "    def transcripts(self):\n",
    "        for path in self.paths():\n",
    "            yield YoutubeTranscript.from_path(path)\n",
    "            \n",
    "    def df_rows(self):\n",
    "        for transcript in self.transcripts():\n",
    "            for text in transcript.sentence_texts():\n",
    "                yield dict(\n",
    "                    channel_title=transcript['channel_title'], \n",
    "                    title=transcript['title'], \n",
    "                    published_at=transcript.published_at,\n",
    "                    text=text,\n",
    "                )\n",
    "                \n",
    "    def df(self):\n",
    "        return pd.DataFrame(list(self.df_rows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class KathyTranscript:\n",
    "    \n",
    "    path = attr.ib()\n",
    "    \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh.read().splitlines():\n",
    "                yield line\n",
    "                \n",
    "    def text(self):\n",
    "        return ' '.join(self.lines())\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self.text(), disable=['tokenizer', 'parser', 'tagger', 'ner'])\n",
    "    \n",
    "    @cached_property\n",
    "    def basename(self):\n",
    "        return os.path.basename(self.path)\n",
    "    \n",
    "    def sentence_texts(self):\n",
    "        for sent in self.doc.sents:\n",
    "            yield sent.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class KathyCorpus:\n",
    "    \n",
    "    root = attr.ib()\n",
    "    \n",
    "    def paths(self):\n",
    "        return glob(os.path.join(self.root, '**/*.txt'), recursive=True)\n",
    "    \n",
    "    def transcripts(self):\n",
    "        for path in self.paths():\n",
    "            yield KathyTranscript(path)\n",
    "            \n",
    "    def df_rows(self):\n",
    "        for transcript in self.transcripts():\n",
    "            for text in transcript.sentence_texts():\n",
    "                yield dict(\n",
    "                    basename=transcript.basename,\n",
    "                    text=text,\n",
    "                )\n",
    "                \n",
    "    def df(self):\n",
    "        return pd.DataFrame(list(self.df_rows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_index(text_series):\n",
    "    \n",
    "    sent_idx = AnnoyIndex(1000)\n",
    "\n",
    "    id_text = list(text_series.iteritems())\n",
    "\n",
    "    for chunk in chunked_iter(tqdm_notebook(id_text), 100):\n",
    "\n",
    "        ids, texts = zip(*chunk)\n",
    "\n",
    "        x = [Sentence(t).sent_order_x() for t in texts]\n",
    "        x = sent_encoder(x)\n",
    "\n",
    "        for i, v in zip(ids, x):\n",
    "            sent_idx.add_item(i, v.data.tolist())\n",
    "\n",
    "    sent_idx.build(10)\n",
    "    \n",
    "    return sent_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_corpus = NewspaperCorpus('../data/kathy2012/newspapers2012/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a812daa6f96419b9c63c9dccaff8895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7437), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_df = news_corpus.df(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d886458cc30241c98510083b89833b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "news_idx = build_index(news_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_corpus = YoutubeCorpus('../data/kathy2012/youtube2012/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_df = yt_corpus.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdc61ae91524fcf805001c66a8a682c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=33027), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "yt_idx = build_index(yt_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "kathy_corpus = KathyCorpus('../data/kathy2012/transcripts2012/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "kathy_df = kathy_corpus.df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f49664a4a8478a8e01a684b7ce3371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3814), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kathy_idx = build_index(kathy_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(df, idx, text, n=10):\n",
    "    for ri in idx.get_nns_by_vector(Sentence(text).embedding(), n):\n",
    "        print(df.iloc[ri].text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is just so wonderful.” \n",
      "\n",
      "This is just so wonderful.” \n",
      "\n",
      "This is a great way to spend a cold winter evening. \n",
      "\n",
      "This is one of the characteristics that make our country great. \n",
      "\n",
      "This is a great opportunity for us today,’’ Walker said. ‘‘ \n",
      "\n",
      "This is great research-based information about how to be successful with whatev- er the topic is.” \n",
      "\n",
      "This is a wonder- ful opportunity. “ \n",
      "\n",
      "This is by far the most ambitious thing I’ve done in my career. \n",
      "\n",
      "This is a very good venue for local artists to show their work,” Lorber said. “ \n",
      "\n",
      "This is all because we’re in the process of negotiating the permanent rule,’’ she said. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query(news_df, news_idx, \"This is wonderful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a huge victory for Wisconsin 's middle class \n",
      "\n",
      "this has been an incredible journey one that has shown \n",
      "\n",
      "this is at a time when we 're supposed to \n",
      "\n",
      "this important piece of the challenge that lies ahead of \n",
      "\n",
      "this is an exciting day this is a day of \n",
      "\n",
      "this is one of our exciting days most exciting days \n",
      "\n",
      "this is one of our exciting days most exciting days \n",
      "\n",
      "this has been an incredible journey 14 months long this \n",
      "\n",
      "but this shows Kosovo as a whole a lot of \n",
      "\n",
      "this fundamental fairness issue we know from Tommy Thompson 's \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query(yt_df, yt_idx, \"This is wonderful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's wonderful. \n",
      "\n",
      "That's wonderful. \n",
      "\n",
      "It's really great. \n",
      "\n",
      "This is Wisconsin. \n",
      "\n",
      "So great. \n",
      "\n",
      "This is very helpful. \n",
      "\n",
      "It's phenomenal. \n",
      "\n",
      "It's a good one. \n",
      "\n",
      "This has been such a great conversation. \n",
      "\n",
      "This has been... this welfare stuff has been getting out of control for years. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query(kathy_df, kathy_idx, \"This is wonderful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
