{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import os\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from annoy import AnnoyIndex\n",
    "from cached_property import cached_property\n",
    "from glob import glob\n",
    "from torchtext.vocab import Vectors\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = Vectors('glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub('[\\s]{2,}|\\n', ' ', text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Sentence:\n",
    "    \n",
    "    text = attr.ib()\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self.text, disable=['parser', 'tagger', 'ner'])\n",
    "    \n",
    "    def tokens(self):\n",
    "        return [t.text for t in self.doc]\n",
    "    \n",
    "    def vector_dan(self):\n",
    "        \n",
    "        embeds = [\n",
    "            vectors[t].squeeze().tolist()\n",
    "            for t in self.tokens()\n",
    "        ]\n",
    "        \n",
    "        return np.mean(embeds, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Segment:\n",
    "    \n",
    "    path = attr.ib()\n",
    "    \n",
    "    def text(self):\n",
    "        with open(self.path) as fh:\n",
    "            return clean_text(fh.read())\n",
    "        \n",
    "    @cached_property\n",
    "    def doc(self):\n",
    "        return nlp(self.text(), disable=['tokenizer', 'parser', 'tagger', 'ner'])\n",
    "    \n",
    "    def sentences(self):\n",
    "        for sent in self.doc.sents:\n",
    "            yield Sentence(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class NewspaperCorpus:\n",
    "    \n",
    "    root = attr.ib()\n",
    "    \n",
    "    def paths(self):\n",
    "        return glob(os.path.join(self.root, '**/*.txt'), recursive=True)\n",
    "    \n",
    "    def segments(self):\n",
    "        for path in tqdm_notebook(self.paths()):\n",
    "            yield Segment(path)\n",
    "            \n",
    "    def sentences(self):\n",
    "        for segment in self.segments():\n",
    "            yield from segment.sentences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = NewspaperCorpus('../data/kathy2012/newspapers2012/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = {\n",
    "    i: sent\n",
    "    for i, sent in enumerate(islice(c.sentences(), 100000))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb605bc3ce57450a9c29dd6764b22040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_dan = AnnoyIndex(300)\n",
    "\n",
    "for i, sent in tqdm_notebook(sents.items()):\n",
    "    idx_dan.add_item(i, sent.vector_dan())\n",
    "    \n",
    "idx_dan.build(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there’s concern out there. \n",
      "\n",
      "I feel very good about where I’m at. \n",
      "\n",
      "I’m sure the neighbors up the road think I’m a lunatic. \n",
      "\n",
      "I just hate the idea of losing it.” \n",
      "\n",
      "I’m just not comfortable about something like this and saw no point to it. \n",
      "\n",
      "I count all the states I’m glad I’m not the governor of.” \n",
      "\n",
      "I’m so hurt, I guess I’m just look- ing for some input into this. \n",
      "\n",
      "And this election isn’t just about what we think about unions. \n",
      "\n",
      "I’m already on the bal- lot. \n",
      "\n",
      "I’m writing now because I have a problem. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = Sentence(\"I'm worried about the economy.\")\n",
    "\n",
    "for ri in idx_dan.get_nns_by_vector(query.vector_dan(), 10):\n",
    "    print(sents[ri].text, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
